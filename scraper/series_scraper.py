# scraper/series_scraper.py
import requests
from bs4 import BeautifulSoup
from database import connect_db, clear_series_table, insert_series

def scrape_series():
    url = 'https://ws-tcg.com/cardlist/'
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    print(f"ğŸŒ ç‹€æ…‹ç¢¼ï¼š{response.status_code}")
    response.encoding = 'utf-8'

    soup = BeautifulSoup(response.text, 'html.parser')
    series_links = soup.select("a[onclick^=showTitleNumberDetail]")
    print(f"ğŸ—‚ æŠ“åˆ°ç³»åˆ—æ•¸ï¼š{len(series_links)}")

    series_data = []
    for a in series_links:
        onclick = a.get('onclick')
        name = a.text.strip()
        if not onclick or not name:
            continue

        # æ“·å– showTitleNumberDetail('##ABC##') ä¸­æ‰€æœ‰ä»£è™Ÿ
        try:
            raw_codes = onclick.split("'")[1]  # e.g. '##abc##def##ghi##'
            code_list = [code for code in raw_codes.split('##') if code]  # å»é™¤ç©ºç™½ï¼Œåˆ†é›¢ä»£è™Ÿ
        except IndexError:
            print(f"âš ï¸ ç„¡æ³•è§£æ onclick: {onclick}")
            continue

        for code in code_list:
            series_data.append((name, code))

    return series_data

def run_series_scraper():
    print("ğŸš€ å•Ÿå‹•ç³»åˆ—çˆ¬èŸ²ç¨‹å¼")
    conn = connect_db()
    if not conn:
        print("âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—")
        return

    clear_series_table(conn)
    series = scrape_series()
    print(f"âœ… å¯¦éš›æŠ“åˆ° {len(series)} ç­†ç³»åˆ—è³‡æ–™")

    for name, code in series:
        insert_series(conn, name, code)

    conn.close()
    print("âœ… ç³»åˆ—è³‡æ–™å¯«å…¥å®Œæˆï¼Œè³‡æ–™åº«é€£ç·šå·²é—œé–‰")
